{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules needed\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "import torch\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import os\n",
    "from transformers import DistilBertTokenizer,DistilBertModel\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss,accuracy_score, classification_report, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "input_dir = '/home/gusmavko@GU.GU.SE/MovieScriptsParticipantsData/'\n",
    "script_dir = '/home/gusmavko@GU.GU.SE/MovieScriptsParticipantsData/Scripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['text'] = [open(script_dir + os.sep + file, \"r\").read() for file in text_df['File_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    tokenized_text = []\n",
    "    sw = stopwords.words(('english'))\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces and convert to lowercase \n",
    "    text = ' '.join(text.split()).lower() \n",
    "    \n",
    "    no_stopword_text = [word for word in text.split() if not word in sw]\n",
    "     \n",
    "    return ' '.join(no_stopword_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df.sample(frac=1).reset_index(drop=True)\n",
    "replacements = {9:8,21:8,20:8,3:15,10:15,12:15,13:15,2:7,18:1,17:1}\n",
    "text_df['Labels'] = text_df['Labels'].replace(replacements)\n",
    "# Manual mapping of integer label to informative label\n",
    "di = {6:'scifi-comedy',19:'action-crime', 4: 'dramedy', 0: 'action-drama',15: 'comedy', 5:'thriller', 1: 'action-comedy', 8:'adventure-drama',16:'scifi',11:'horror-mystery',14:'crime-thriller',7:'family'}\n",
    "text_df= text_df.replace({\"Labels\": di})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.Labels.value_counts().plot(kind='bar',xlabel = 'Genre', ylabel = '# of scripts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing accuracy scores for different classifiers from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(train_x,train_y,test_x,test_y,classifier):\n",
    "    vectorizer = TfidfVectorizer(max_features=10000)\n",
    "    vectorizer.fit(text_df['text'])\n",
    "    train_x_vec = vectorizer.transform(train_x)\n",
    "    test_x_vec = vectorizer.transform(test_x)\n",
    "    classifier.fit(train_x_vec,train_y)\n",
    "    predictions = classifier.predict(test_x_vec)\n",
    "    #for test, prediction, label in zip(test_x_vec, predictions, test_y):\n",
    "    #    if prediction != label:\n",
    "    #        print(test, 'has been classified as ', prediction, 'and should be ', label)\n",
    "    accuracy = f1_score(predictions,test_y,average='weighted')\n",
    "    accuracy = 100*accuracy\n",
    "    \n",
    "    acc = round((accuracy_score(predictions,test_y)*100),2)\n",
    "    return round(accuracy,2),acc\n",
    "    \n",
    "# split into Train/Test to extract TF-IDF features and define the classifiers from sklearn I will use on the data    \n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(text_df['text'],text_df['Labels'],test_size=0.2)\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "svm = svm.SVC(C=1.0, kernel='linear', degree=1, gamma='auto')\n",
    "kn = KNeighborsClassifier(5)\n",
    "lr = LogisticRegression(random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for Naive Bayes Multinomial Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nb = get_accuracy(Train_X,Train_Y,Test_X, Test_Y, nb)\n",
    "acc_nb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_svm = get_accuracy(Train_X,Train_Y,Test_X, Test_Y, svm)\n",
    "acc_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kn = get_accuracy(Train_X,Train_Y,Test_X, Test_Y, kn)\n",
    "acc_kn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_acc = get_accuracy(Train_X,Train_Y,Test_X, Test_Y, lr)\n",
    "log_reg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.read_csv('Train.csv')\n",
    "replacements = {9:8,21:8,20:8,3:15,10:15,12:15,13:15,2:7,18:1,17:1}\n",
    "df_text['Labels'] =df_text['Labels'].replace(replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT embeddings as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def script_reader(file_name):\n",
    "    script_path = os.path.join(cur_dir,script_dir,file_name)\n",
    "    with open (script_path, \"r\") as myfile:\n",
    "        script =  myfile.read()\n",
    "        return script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the scripts are so long, I had to feed the model sequences of 512 length \n",
    "class ScriptDataset(Dataset):\n",
    "    def __init__(self, file_path,tokenizer,seq_len = 510):\n",
    "        #Sequence length = Maximum possible sequence length(512) which can be fed to model - start and end tokens(2) \n",
    "        self.file_path =  file_path\n",
    "        self.script = script_reader(self.file_path)\n",
    "        #Each script is loaded only when it is being processed and deleted once tokenization and encoding is done\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.tokens = self.tokenizer.tokenize(self.script)\n",
    "        del self.script\n",
    "        self.sequences = [self.tokens[i:i+self.seq_len] for i in range(0,len(self.tokens),self.seq_len)][:-1]\n",
    "        #Drops last sequence of unequal length\n",
    "        del self.tokens\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.tokenizer.encode(self.sequences[idx], add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_embedding(file_path,tokenizer,model,batch_size = 2):\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    \n",
    "    script_set = ScriptDataset(file_path,tokenizer)\n",
    "    batch_loader = DataLoader(script_set,batch_size = batch_size, shuffle = False,drop_last=False)\n",
    "    del script_set\n",
    "    \n",
    "    seq_embeddings = []\n",
    "    for i,batch in enumerate(batch_loader):\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            seq_embed = model(batch)[0][:,0,:]\n",
    "            #Collecting only the final hidden state corresponding to CLS token which can be used as sequence embedding\n",
    "        del batch\n",
    "        seq_embeddings.append(seq_embed)\n",
    "        del seq_embed\n",
    "    del batch_loader\n",
    "           \n",
    "    return torch.cat(seq_embeddings,dim = 0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embeddings = []\n",
    "for i in range(len(df_text)):\n",
    "    Embeddings.append(create_bert_embedding(df_text.File_Name[i],tokenizer,model))\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/gusmavko@GU.GU.SE/MovieScriptsParticipantsData/s_embeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(Embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "df_text['Embeds'] = Embeddings\n",
    "\n",
    "with open('/home/gusmavko@GU.GU.SE/MovieScriptsParticipantsData/df_raw_embeds2.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_text, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('Pickling completed')\n",
    "#Saving the dataframe so that further analysis can start from this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be able to start from here by loading pickled file whenever I want to process it\n",
    "import pickle\n",
    "df_embed_path = '/home/gusmavko@GU.GU.SE/MovieScriptsParticipantsData/df_raw_embeds.pickle'\n",
    "\n",
    "with open(df_embed_path, 'rb') as handle:\n",
    "    df_text = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do kfold cross validation to get accuracy scores\n",
    "df_text[\"kfold\"] = -1\n",
    "skf = StratifiedKFold()\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X=df_text, y=df_text['Labels'].values)):\n",
    "                    df_text.loc[val_idx, 'kfold'] = fold\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new data frame with arrays that contain the features as values\n",
    "def create_df_embeds(feat_array, df):\n",
    "    cols_num = feat_array[0].shape[0]\n",
    "    col_names = ['feat_' + str(i+1) for i in range(cols_num)]\n",
    "    df_feat = pd.DataFrame(data = feat_array,columns = col_names)\n",
    "    df_fit = pd.concat([df, df_feat], axis=1)\n",
    "    return df_fit,col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train(df_fit,classifier,feat_cols,label_col = 'Labels'):\n",
    "    \n",
    "    folds = df_fit.kfold.nunique()\n",
    "    FOLD_MAPPPING = {fold:list(set(range(folds)) - set([fold]))  for fold in range(folds)}\n",
    "    clfs = [classifier]*folds\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    \n",
    "    for FOLD in range(5):\n",
    "        \n",
    "        train_df = df_fit[df_fit.kfold.isin(FOLD_MAPPPING.get(FOLD))].reset_index(drop=True)\n",
    "        valid_df = df_fit[df_fit.kfold==FOLD].reset_index(drop=True)\n",
    "        \n",
    "        clf = clfs[FOLD]\n",
    "        clf.fit(train_df[feat_cols].values, train_df[label_col])\n",
    "        \n",
    "        train_probs = clf.predict_proba(train_df[feat_cols].values)\n",
    "        train_preds = clf.predict(train_df[feat_cols].values)\n",
    "        \n",
    "        train_accuracy = accuracy_score(train_df[label_col], train_preds)\n",
    "        train_loss = log_loss(train_df[label_col], train_probs)\n",
    "                        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        valid_probs = clf.predict_proba(valid_df[feat_cols].values)\n",
    "        valid_preds = clf.predict(valid_df[feat_cols].values)\n",
    "\n",
    "        valid_accuracy = accuracy_score(valid_df[label_col], valid_preds)\n",
    "     \n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "    mean_train_loss,std_train_loss = np.mean(train_losses),np.std(train_losses)\n",
    "    mean_train_accuracy,std_train_accuracy  = np.mean(train_accuracies),np.std(train_accuracies)\n",
    "        \n",
    "    mean_valid_loss,std_valid_loss = np.mean(valid_losses),np.std(valid_losses)\n",
    "    mean_valid_accuracy,std_valid_accuracy  = np.mean(valid_accuracies),np.std(valid_accuracies)\n",
    "\n",
    "    print(f'train loss = {mean_train_loss} with {np.round((std_train_loss/mean_train_loss)*100, 2)}% error')\n",
    "\n",
    "    print(f'train accuracy = {mean_train_accuracy} with {np.round((std_train_accuracy/mean_train_accuracy)*100, 2)}% error')\n",
    "    print(f'valid accuracy = {mean_valid_accuracy} with {np.round((std_valid_accuracy/mean_valid_accuracy)*100, 2)}% error')\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123 # setting seed for reproducibility of the experiments\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "mean_array = np.stack((df_text.Embeds.apply(lambda x: x.mean(axis = 0)).values),axis = 0)\n",
    "df_mean,cols = create_df_embeds(mean_array, df_text)\n",
    "classif = LogisticRegression(random_state=seed)\n",
    "LR_clfs = train(df_mean,classif,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = [0.3786346396965866, 0.37041719342604296, 0.37420986093552466, 0.37965887555274797, 0.36765634870499053]\n",
    "valid_accuracies = [0.24242424242424243, 0.2702020202020202, 0.25252525252525254, 0.25569620253164554, 0.2683544303797468]\n",
    "\n",
    "def make_pct(l):\n",
    "    return [round((x*100),2) for x in l]\n",
    "train_accuracies = make_pct(train_accuracies)\n",
    "valid_acuuracies = make_pct(valid_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = range(1,6)\n",
    "plt.plot(folds, train_accuracies, 'g', label='Train accuracy')\n",
    "plt.plot(folds, valid_acuuracies, 'b', label='Test accuracy')\n",
    "plt.title('Training and Test accuracy')\n",
    "plt.xlabel('Folds')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,100])\n",
    "plt.xticks([1,2,3,4,5])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
